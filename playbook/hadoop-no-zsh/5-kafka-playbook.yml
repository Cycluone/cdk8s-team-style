- hosts: hadoops
  remote_user: root
  vars:
    tar_gz_file_name: "kafka_2.11-2.4.1.tgz"
    install_folder: "/usr/local"
    zookeeper_home_path: "{{ install_folder }}/apache-zookeeper-3.5.7-bin"
    home_path: "{{ install_folder }}/kafka_2.11-2.4.1"
    config_path: "{{ home_path }}/config"
  tasks:
    - name: echo JAVA_HOME
      debug:
        msg: "'{{ lookup('env', 'JAVA_HOME') }}' -- is environment variable"

    - name: get environment variable JAVA_HOME
      set_fact:
        JAVA_HOME_VAR: "{{ lookup('env', 'JAVA_HOME')}}"
    - name: check JAVA_HOME environment variable
      fail:
        msg: "Environment variable JAVA_HOME is not defined or empty"
      when: JAVA_HOME_VAR == ""

    - name: check zookeeper folders exist
      stat:
        path: "{{ zookeeper_home_path }}"
      register: register_result
    - name: check zookeeper folders exist fail
      fail:
        msg: "check zookeeper folders exist fail"
      when: not register_result.stat.exists

    - name: copy tar.gz
      copy:
        src=/opt/software/{{ tar_gz_file_name }}
        dest={{ install_folder }}

    - name: tar gz
      shell:
        chdir={{ install_folder }}
        tar zxf {{ tar_gz_file_name }}

    - name: remove tar.gz file
      file:
        path: "{{ install_folder }}/{{ tar_gz_file_name }}"
        state: absent

    - name: create logs directory
      file:
        path: "{{ item }}"
        state: directory
      with_items:
        - "{{ home_path }}/logs"




- hosts: header1
  remote_user: root
  vars:
    install_folder: "/usr/local"
    home_path: "{{ install_folder }}/kafka_2.11-2.4.1"
    config_path: "{{ home_path }}/config"
    logs_path: "{{ home_path }}/logs"
  tasks:
    - name: copy server.properties
      copy:
        src="{{ config_path }}/server.properties"
        dest="{{ config_path }}/server.properties.back"
    - name: remove server.properties
      file:
        path: "{{ config_path }}/server.properties"
        state: absent
    - name: create server.properties
      file:
        path="{{ config_path }}/{{ item }}"
        state=touch
        mode=777
      with_items:
        - server.properties
    - name: set server.properties
      blockinfile:
        path: "{{ config_path }}/server.properties"
        marker: ""
        block: |
          #broker的全局唯一编号，不能重复
          broker.id=1
          #删除topic功能使能
          delete.topic.enable=true
          #配置连接Zookeeper集群地址，末尾的/kafka可选，但是建议配置上，因为注册到ZooKeeper的除了kafka可能还有其他服务，增加根目录便于区分
          zookeeper.connect=header1:2181,worker1:2181,worker2:2181/kafka
          num.network.threads=3
          num.io.threads=8
          socket.send.buffer.bytes=102400
          socket.receive.buffer.bytes=102400
          socket.request.max.bytes=104857600
          log.dirs={{ logs_path }}
          num.partitions=1
          num.recovery.threads.per.data.dir=1
          offsets.topic.replication.factor=1
          transaction.state.log.replication.factor=1
          transaction.state.log.min.isr=1
          log.retention.hours=168
          log.segment.bytes=1073741824
          log.retention.check.interval.ms=300000
          zookeeper.connection.timeout.ms=6000
          group.initial.rebalance.delay.ms=0
    - name: remove blank lines blockinfile
      lineinfile :
        path: "{{ config_path }}/server.properties"
        regexp: "^$"
        state: absent





- hosts: worker1
  remote_user: root
  vars:
    install_folder: "/usr/local"
    home_path: "{{ install_folder }}/kafka_2.11-2.4.1"
    config_path: "{{ home_path }}/config"
    logs_path: "{{ home_path }}/logs"
  tasks:
    - name: copy server.properties
      copy:
        src="{{ config_path }}/server.properties"
        dest="{{ config_path }}/server.properties.back"
    - name: remove server.properties
      file:
        path: "{{ config_path }}/server.properties"
        state: absent
    - name: create server.properties
      file:
        path="{{ config_path }}/{{ item }}"
        state=touch
        mode=777
      with_items:
        - server.properties
    - name: set server.properties
      blockinfile:
        path: "{{ config_path }}/server.properties"
        marker: ""
        block: |
          #broker的全局唯一编号，不能重复
          broker.id=2
          #删除topic功能使能
          delete.topic.enable=true
          #配置连接Zookeeper集群地址，末尾的/kafka可选，但是建议配置上，因为注册到ZooKeeper的除了kafka可能还有其他服务，增加根目录便于区分
          zookeeper.connect=header1:2181,worker1:2181,worker2:2181/kafka
          num.network.threads=3
          num.io.threads=8
          socket.send.buffer.bytes=102400
          socket.receive.buffer.bytes=102400
          socket.request.max.bytes=104857600
          log.dirs={{ logs_path }}
          num.partitions=1
          num.recovery.threads.per.data.dir=1
          offsets.topic.replication.factor=1
          transaction.state.log.replication.factor=1
          transaction.state.log.min.isr=1
          log.retention.hours=168
          log.segment.bytes=1073741824
          log.retention.check.interval.ms=300000
          zookeeper.connection.timeout.ms=6000
          group.initial.rebalance.delay.ms=0
    - name: remove blank lines blockinfile
      lineinfile :
        path: "{{ config_path }}/server.properties"
        regexp: "^$"
        state: absent






- hosts: worker2
  remote_user: root
  vars:
    install_folder: "/usr/local"
    home_path: "{{ install_folder }}/kafka_2.11-2.4.1"
    config_path: "{{ home_path }}/config"
    logs_path: "{{ home_path }}/logs"
  tasks:
    - name: copy server.properties
      copy:
        src="{{ config_path }}/server.properties"
        dest="{{ config_path }}/server.properties.back"
    - name: remove server.properties
      file:
        path: "{{ config_path }}/server.properties"
        state: absent
    - name: create server.properties
      file:
        path="{{ config_path }}/{{ item }}"
        state=touch
        mode=777
      with_items:
        - server.properties
    - name: set server.properties
      blockinfile:
        path: "{{ config_path }}/server.properties"
        marker: ""
        block: |
          #broker的全局唯一编号，不能重复
          broker.id=3
          #删除topic功能使能
          delete.topic.enable=true
          #配置连接Zookeeper集群地址，末尾的/kafka可选，但是建议配置上，因为注册到ZooKeeper的除了kafka可能还有其他服务，增加根目录便于区分
          zookeeper.connect=header1:2181,worker1:2181,worker2:2181/kafka
          num.network.threads=3
          num.io.threads=8
          socket.send.buffer.bytes=102400
          socket.receive.buffer.bytes=102400
          socket.request.max.bytes=104857600
          log.dirs={{ logs_path }}
          num.partitions=1
          num.recovery.threads.per.data.dir=1
          offsets.topic.replication.factor=1
          transaction.state.log.replication.factor=1
          transaction.state.log.min.isr=1
          log.retention.hours=168
          log.segment.bytes=1073741824
          log.retention.check.interval.ms=300000
          zookeeper.connection.timeout.ms=6000
          group.initial.rebalance.delay.ms=0
    - name: remove blank lines blockinfile
      lineinfile :
        path: "{{ config_path }}/server.properties"
        regexp: "^$"
        state: absent




- hosts: hadoops
  remote_user: root
  vars:
    install_folder: "/usr/local"
    home_path: "{{ install_folder }}/kafka_2.11-2.4.1"
  tasks:
    - name: start kafka
      shell: "{{ item }}"
      with_items:
        - "sh {{ home_path }}/bin/kafka-server-start.sh -daemon {{ home_path }}/config/server.properties"


- hosts: header1
  remote_user: root
  tasks:
    - debug:
        msg:
          - "启动命令：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-server-start.sh -daemon /usr/local/kafka_2.11-2.4.1/config/server.properties"
          - "停止命令：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-server-stop.sh"
          - "查看所有topic：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-topics.sh --zookeeper header1:2181,worker1:2181,worker2:2181/kafka --list"
          - "查看指定topic：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-topics.sh --zookeeper header1:2181,worker1:2181,worker2:2181/kafka --describe --topic myTopicName"
          - "创建指定topic，topic 命名不能有下划线、点：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-topics.sh --zookeeper header1:2181,worker1:2181,worker2:2181/kafka --create --replication-factor 3 --partitions 2 --topic myTopicName"
          - "删除指定topic：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-topics.sh --zookeeper header1:2181,worker1:2181,worker2:2181/kafka --delete --topic myTopicName"
          - "发送消息：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-console-producer.sh --broker-list header1:9092,worker1:9092,worker2:9092 --topic myTopicName"
          - "接收消息，只接收当前的：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-console-consumer.sh --bootstrap-server header1:9092,worker1:9092,worker2:9092 --topic myTopicName"
          - "接收消息，包括前面的消息：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-console-consumer.sh --bootstrap-server header1:9092,worker1:9092,worker2:9092 --from-beginning --topic myTopicName"
          - "修改分区数：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-topics.sh --zookeeper header1:2181,worker1:2181,worker2:2181/kafka --alter --topic myTopicName --partitions 6"
    - debug:
        msg:
          - "查看当前消费者列表：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-consumer-groups.sh --bootstrap-server header1:9092,worker1:9092,worker2:9092 --list"
          - "根据消费者名查看当前消费情况：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-consumer-groups.sh --bootstrap-server header1:9092,worker1:9092,worker2:9092 --describe --group 前面的查询出的消费者"
    - debug:
        msg:
          - "生产者压力测试：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-producer-perf-test.sh  --topic myTopicName --record-size 100 --num-records 100000 --throughput -1 --producer-props bootstrap.servers=header1:9092,worker1:9092,worker2:9092"
          - "参数：record-size是一条信息有多大，单位是字节"
          - "参数：num-records是总共发送多少条信息。"
          - "参数：throughput 是每秒多少条信息，设成-1，表示不限流，可测出生产者最大吞吐量"
          - "测试结果：100000 records sent, 92764.378479 records/sec (8.85 MB/sec), 161.54 ms avg latency, 688.00 ms max latency, 15 ms 50th, 626 ms 95th, 678 ms 99th, 687 ms 99.9th"
          - "测试结果表示：一共写入10w条消息，吞吐量为 8.85 MB/sec，每次写入的平均延迟为 161.54 ms 毫秒，最大的延迟为 688.00 毫秒"
    - debug:
        msg:
          - "消费者压力测试：sh /usr/local/kafka_2.11-2.4.1/bin/kafka-consumer-perf-test.sh --broker-list header1:9092,worker1:9092,worker2:9092 --topic myTopicName --fetch-size 10000 --messages 100000 --threads 1"
          - "参数：fetch-size 指定每次fetch的数据的大小"
          - "参数：messages 总共要消费的消息个数"
          - "测试结果：2021-07-10 01:37:13:088, 2021-07-10 01:37:13:601, 9.5436, 18.6036, 100075, 195077.9727, 1625852233293, -1625852232780, -0.0000, -0.0001"
          - "测试结果表示：开始测试时间，测试结束数据，共消费数据 9.5436MB，吞吐量 18.6036MB/s，共消费 100075 条，平均每秒消费 195077.9727 条"
    - debug:
        msg: "kafka 监控工具：https://www.kafka-eagle.org/index.html"
















